\chapter{Анализ предметной области}

В данном разделе будут представлены классификация основных типов сигналов и изучены основные методов формирования помехи, описаны и разделены машинное обучение и глубокое обучение и представлены и сравнены нейронные сети, подходящие под поставленную цель.

\section{Классификация основных типов сигналов и модуляций}

\subsection*{Управляющий диапазон}
Современные коммерческие дроны в основном работают в стандартном Wi-Fi диапазоне (2.4 ГГц и 5 ГГц) \cite{wifidiapazon}. Даже базовые коммерческие дроны обычно имеют несколько запрограммированных автоматических функций, таких как отслеживание положения дрона или функция <<возврат домой>>, срабатывающая в случае потери управляющего сигнала. Для этих функций используется <<Глобальная Навигационная Система Позиционирования>> (GNPS), однако уже началась интеграция 4G и 5G для управления дронами \cite{4gand5g}.

\subsection*{Модуляции}

На данный момент для управления дронами используются сигналы с расширенным спектром \cite{spreadspecsignals}. Эти типы сигналов обладают хорошей устойчивостью к помехам, как естественным (шум) так и преднамеренным (глушение). Принцип расширения спектра заключается в в модуляции \cite{signalmodulation} узкополосного сигнала, содержащего информацию, псевдослучайным широкополосным сигналом. При такой модуляции получается сигнал с расширенным спектром.

\section{Способы формирования помехи}

Постановка помех --- это метод нейтрализации этих приемников сигнала. Самыми основными методами формирования помехи: с помощью шума и активного сигнала \cite{radioelecpomeh}. Важно отметить, что целью воздействия всегда является приемник, так как требуется меньшая мощность помех, чтобы обеспечить достаточное отношение помех к сигналу.

\subsection*{Формирования помехи с помощью шума}

Принцип этого типа формирования помехи заключается в передаче шума требуемой формы, мощности и полосы пропускания, который используется для перекрытия изначального сигнала и предотвращая передачи между приемником и передатчиком. В результате уровень помех на стороне приемника увеличивается, что увеличивает отношение помех к сигналу. Этот тип глушения широко используется \cite{uavneutralize} против коммуникационных и не коммуникационных сигналов. Не коммуникационные сигналы обычно \cite{uavneutralize} используются в области активной радиолокации, следовательно, рассматриваться не будут.

\subsubsection*{Узкополосный шум}

Этот тип полосы пропускания определяется частотным спектром изначального сигнала, (см. рисунок \ref{img:narrowband}). В связи с тем, что в настоящее время для целей связи широко используются сигналы с расширенным спектром, этот шум обычно непригоден для создания помех БПЛА.

\img{70mm}{narrowband}{Спектр узкополосных шумовых помех}

\FloatBarrier

\subsubsection*{Сверхширокополосный шум}

Этот тип шумовых помех охватывает всю полосу пропускания сигнала связи, (см. рисунок \ref{img:ultrawodeband}). Его недостатком является необходимость высокого уровня мощности для обеспечения достаточного отношения шума к сигналу для эффективного формирования помехи \cite{advanddisadvuwb}. В результате сверхширокополосный шум снижает пропускную способность канала системы. Это приводит к уменьшению отношения сигнала к шуму на стороне приемника и увеличению количества ошибок передачи.

\img{70mm}{ultrawodeband}{Спектр сверх широких шумовых помех}

\FloatBarrier

\subsubsection*{Развертка шума}
 
Принцип этого типа формирования помехи заключается в быстром перемещении относительно узкополосного сигнала по всему интересующему диапазону. Сигналом помехи может быть шум или импульсный сигнал. Забивается только одна частота. Хотя охватывается весь спектр скачкообразной перестройки частоты, скачки выполнять не обязательно. Из-за слабой мощности сигнала GPS также происходит экономия необходимой мощности помехового сигнала для достижения требуемого отношения помех к сигналу. Поскольку большинство БПЛА имеют некоторую функцию автопилота (например, упомянутую выше функцию «возврата домой»), глушение сигналов GPS является одним из способов нейтрализовать дроны, не уничтожая их.

\subsubsection*{Интеллектуальный шум}

При этом типе помех воздействуют только на необходимые сигналы в спектре, чтобы предотвратить связь между приемником и передатчиком. Однако требуется предварительное знание типа сигнала помехи. Для этого типа глушения необходим анализ протоколов, используемых различными производителями приемников. Из анализа протоколов и входящего сигнала можно определить критические точки, которые могут быть затронуты. Затем можно создать сигнал с аналогичными параметрами. Этот тип глушения является наиболее энергоэффективным и эффективным, но и наиболее технологически требовательным \cite{intellectnoise}.

\subsection*{Формирования помехи с помощью активного сигнала}

Этот способ также называется подделыванием. В отличие от шума, он не направлен на создание помех в определенной части спектра и, таким образом, на предотвращение передачи. Его цель --- создать и отправить сигнал, аналогичный исходному сигналу. Такой сигнал с более высоким уровнем мощности, чем у законного передатчика, затем используется для обмана приемника. Это может иметь различные последствия, например, сбить с толку GPS. Как следует из описанного принципа, конструкция такого глушителя более сложна по сравнению с шумовым глушителем. Для шумовых помех требуется использовать простой приемник, чтобы найти интересующий сигнал в спектре. В случае подделывания ответа необходимо принять исходный сигнал, изменить его и отправить новый ложный сигнал достаточной мощности, чтобы, приемник <<поверил>>, что это настоящий контролирующий сигнал.

Декодирование исходного сигнала или его протокола является сложным \cite{analisanddecod} и требует обратного проектирования, чтобы понять его структуру. Кроме того, требуется учитывать влияние окружающей среды, поскольку исходный сигнал может колебаться от различных воздействий колеблется (например, для GPS необходимо учитывать положение спутника и погоду). Некоторые неблагоприятные воздействия на передачу значительно устранены в приемниках цели: например, в GPS колебания амплитуды уменьшаются с помощью схем автоматической регулировки усиления \cite{autogaincontrol}. Однако по принципу своей работы эта система делает устройство более склонным к глушению отклика --- обман GPS может привести к путанице в данных навигации \cite{gpsspoofing}.

Еще одной проблемой, особенно с военной техникой, является шифрование, которое сильно усложняет получение изначального сигнала.

Хотя существуют различные способы перехвата и классификации сигналов \cite{analisanddecod}, эти методы обычно требуют много времени. Таким образом возникает проблема реагирования в режиме реального времени.

\section{Машинное обучение}

Для того, чтобы не только перехватить и расшифровать, но и преобразовать сигнал, стоит использовать методы машинного и глубокого обучения. Эти методы помогают оптимизировать прием и расшифровку сигнала более эффективно, чем классические алгоритмы \cite{deeplearnofdm}, следовательно, стоит рассмотреть возможность использования машинного или глубокого обучения для преобразования сигнала.

\subsection*{Базовое понятие машинного обучения}

\textbf{Ассоциация машинного обучения} основана на поиске связей между переменными в большой базе данных. Метод используется для установления сильных правил, обнаруженных в базе данных с помощью некоторых мер интересности \cite{introdmachlearn}. Этот основанный на правилах подход генерирует также новые правила по мере анализа дополнительных данных. Конечной целью, исходя из достаточно большого набора данных, помочь машине имитировать выделение и создание возможности нахождения абстрактных ассоциаций из новых неклассифицированных данных.

\textbf{Классификация машинного обучения} --- базовая проблема, которая часто решается при работе с большими объемами данных. Требуется классифицировать большой набор входных данных на несколько выходных классов. Простейшей классификацией явялется разделение на два класса ($A$ и $B$). После обучения классификатора прошлыми данными правило классификации может выглядеть как выбор из двух возможных вариантов:
\begin{equation}
	C = \begin{cases}
		A, \text{если } condition_{1} > \theta_{1} \text{ и } condition_{2} > \theta_{2}, \\
		B, \text{иначе}.
	\end{cases}
\end{equation}


Многие приложения машинного обучения имеют разные типы классификаторов. Эти классификаторы часто используются для распознавания образов. Примером может служить преобразование рукописного текста в компьютерную запись. Здесь много переменных, так как у каждого человека разный почерк (наклон, размер шрифта, тип пера и т. д.). Проблема с разным почерком заключается в том, что у не существует стандартизированной системы того, как должны выглядеть отдельные буквы. Следовательно, уместно использовать классификатор на основе машинного обучения, который извлекает формулу из большой выборки обучающих данных, в которую, хотя и не все, удается включить большинство шрифтов. Другим примером может быть распознавание дорожных знаков в автономных транспортных средствах. Здесь изображение с камеры представляет собой систему отдельных пикселей. Основываясь на контрасте, цветах и   узорах, можно было идентифицировать соответствующий дорожный знак. Кроме того, такие классификаторы могут быть использованы в медицине (для диагностики), распознавания речи или биометрии \cite{introdmachlearn}.

Изучение правил или формул извлечения данных создает простую модель, описывающую эти данные. Это дает объяснение заданного набора данных, которое было бы невозможно получить при анализе этих данных человеком (такая обработка заняла бы нереальное количество времени). Еще одним преимуществом этого подхода является сжатие. Формула является гораздо более простым объяснением проблемы, чем сами данные. В результате это экономит память и вычислительные требования на компьютере. Другим выгодным применением может быть установка границ, когда классификатор выбирает входные данные, которые не попадают в выбранные классы. Эти входные данные могут потребовать особого внимания при обработке данных \cite{introdmachlearn}.

\textbf{Регрессия машинного обучения} --- модель взаимосвязи между несколькими входными переменными и выходной зависимой переменной.

Регрессия делится на несколько видов:
\begin{itemize}
	\item[-] линейная --- метод для моделирования отношений между одной независимой входной переменной (переменной функции) т выходной зависимой переменной;
	\item[-] множественная линейная --- взаимосвязь создается между несколькими входными переменными и выходной зависимой переменной;
	\item[-] полиномиальная --- модель становится нелинейной комбинацией входным переменных, то есть среди них могут быть экспоненциальные переменные;
	\item[-] логистическая --- метод классификации данных по двум классам с помощью сигмоидальной функции. Этот тип регрессии обычно обычно используется для распределения данных по классам вероятности.
\end{itemize}

\subsection*{Категории машинного обучения}

Машинное обучение можно разделить на несколько категорий: контролируемое обучение, неконтролируемое, полууправляемое и обучение с подкреплением.

\subsubsection*{Контролируемое обучение}

В эту категорию попадают как проблемы регрессии, так и проблемы классификации. Имеется набор входных данных $X$ и требуемых выходов $Y$ , задача состоит в том, чтобы найти функцию или формулу, описывающую связь между X и Y. Подход машинного обучения предполагает модель, определенную как:
\begin{equation}
	Y = g(X | \theta),
\end{equation}
где $g()$ — модель, $\theta$ — ее параметр. $Y$ — номер регрессии и код класса для классификации. $g()$ — функция регрессии или дискриминаторная функция. Алгоритм машинного обучения затем оптимизирует $\theta$ так, чтобы ошибка аппроксимации была минимальной по отношению к обучающему набору данных. Входной набор данных $X$ обычно делится на обучающие и тестовые данные. Данные обучения используются для создания модели зависимости между входными данными $X$ и выходными данными $Y$ и, таким образом, для нахождения $g()$. Тестовые данные используются для измерения точности модели, таким образом, описанная оптимизация $\theta$. Поэтому для контролируемого обучения необходимо иметь достаточный набор обучающих данных $X$, для которых известны правильные выходные данные $Y$. Эти выходные данные предоставляются «учителем» (экспертом, создающим алгоритм). Поэтому эта категория называется обучением с учителем \cite{artificialintel}.

\subsubsection*{Неконтролируемое обучение}

В неконтролируемом обучении нет «учителя», и нет доступных правильных результатов. Доступны только входные данные, и цель состоит в том, чтобы найти закономерность во входных данных. Во входном наборе одни паттерны появляются чаще других, и мы хотим знать, что вообще происходит, а что нет. В статистике эта задача называется функцией плотности вероятности \cite{surverymashin}.
Одним из методов определения функции плотности вероятности является так называемая кластеризация. Здесь мы пытаемся найти разные группы со схожими параметрами во входных данных. Примером кластеризации является сжатие изображений. В этом случае входными данными являются пиксели со значениями RGB. Алгоритм кластеризации объединяет пиксели с похожими цветами в одну группу. Созданные таким образом группы соответствуют цветам, часто встречающимся на изображении. Таким образом можно значительно уменьшить количество используемых цветов (или количество битов, присваиваемых одному цвету) и таким образом добиться требуемого сжатия \cite{introdmachlearn}.

\subsubsection*{Полууправляемое обучение}

Полууправляемое обучение представляет собой комбинацию двух вышеупомянутых типов, где обучающие данные доступны с известными выходными данными и без них \cite{surverymashin}. Имеется набор неразмеченных данных, а для части из них у есть дополнительная информация (небольшое количество размеченных данных). Полууправляемое обучение имеет большое практическое значение, так как во многих случаях маркируется только часть данных, а получение остальных меток может быть весьма затруднительным (например, необходимость в специальных устройствах или дорогостоящие и медленные эксперименты). Есть две задачи, которые решает полууправляемое обучение \cite{transactonne}.
\begin{enumerate}[label=\arabic*)]
	\item Индуктивное полууправляемое обучение --- предсказание меток для данных тестирования.
	\item Трансдуктивное полууправляемое обучение --- маркировка неразмеченных данных в обучающем наборе.
\end{enumerate}

\subsubsection{Обучение с подкреплением}

В обучении с подкреплением проблемы решаются с помощью последовательности действий, использующих правила проб и ошибок . Одно действие не важно — важно, чтобы вся последовательность приводила к правильному результату. В этом основное отличие от предыдущих категорий, которые основывались на использовании исторических данных, тогда как алгоритмы обучения с подкреплением обучаются на предыдущих попытках решить заданную сетевую задачу \cite{surverymashin}. На рисунке \ref{img:strategia} показаны пять основных элементов, необходимых для обучения с подкреплением \cite{transactonne}:

\img{45mm}{strategia}{Обучение с подкреплением}

\FloatBarrier

\begin{itemize}
	\item[-]  агент: объект, который может выполнить действие $A_{t}$ и получить вознаграждение $R_{t}$;
	\item[-] среда: представление реального мира, в котором действует агент;
	\item[-] вознаграждение $R_{t}$: обратная связь агенту относительно выполненного действия $A_{t}$;
	\item[-] стратегия: обзор каждого состояния $S_{t}$ по отношению к выполненному действию $A_{t}$;
	\item[-] значение функции: представляет, насколько хорошим является состояние $S_{t}$, но на самом деле это ожидаемое вознаграждение $R_{t}$ в будущем по отношению к достигнутому состоянию $S_{t}$.
\end{itemize}

Таким образом, цель обучения с подкреплением состоит в том, чтобы выбрать стратегию (выполнение определенных действий $A_{t}$), которая максимизирует предопределенную функцию вознаграждения.

\section{Глубокое обучение}

Другой специфический класс машинного обучения — это глубокое обучение (ГО), где несколько слоев используются для создания искусственной нейронной сети, которая должна быть в состоянии принимать <<умные>> решения без какого-либо вмешательства человека. Принцип работы алгоритмов ГО заключается в извлечении информации из необработанных данных через несколько слоев нелинейных процессоров (отдельных слоев искусственной нейронной сети) с целью предсказания или выполнения действия относительно итоговой цели. Эти действия осуществляются без явного программирования. Базовыми моделями ГО, используемыми для этих целей, являются уже упомянутые нейронные сети. Однако к моделям ГО можно отнести только сети с достаточным количеством скрытых слоев (обычно более одного). Основным преимуществом ГО перед классическим машинным обучением является автоматическое извлечение паттернов \cite{deeplearninmob}.

Глубокое обучение — это разновидность машинного обучения, имитирующая биологические нейронные сети. DL позволяет компьютерам создавать сложные концепции из простых. Текущие операции в нейронной сети обычно определяются как комбинация определенной группы единиц с нелинейной функцией активации. Эта комбинация подлежит взвешиванию. Такие операции вместе с единицами вывода образуют так называемые слои \cite{deeplearninmob}.

\subsection*{Модели глубокого обучения}

В разделе описания машинного обучения описаны модели контролируемого, неконтролируемого, полууправляемого обучения и обучения с подкреплением, которые используются в разных областях. Архитектура глубокого обучения может использоваться во всех этих областях.

\subsubsection*{Многослойный персептрон --- МСП}

МСП --- это математическая функция, которая присваивает выходные значения набору входных значений. Сложная функция состоит из множества простых функций. МСП — это первая конструкция искусственной нейронной сети, состоящая как минимум из трех слоев (один входной, один скрытый и один выходной). Нейроны в каждом слое связаны со всеми нейронами из предыдущего и следующего слоя. Это приводит к большому количеству весов конфигураций. На рисунке \ref{img:mlp} показан пример МСП с двумя скрытыми слоями. Раньше МСП широко использовались, но в настоящее время их популярность снижается из-за их сложности и средней производительности. В настоящее время МСП обычно используются в качестве строительного блока для более сложных алгоритмов.

\img{80mm}{mlp}{Многослойный персептрон}

\FloatBarrier

\subsubsection*{Ограниченная машина Больцмана --- ОМБ}

ОМБ изначально были разработаны для целей неконтролируемого обучения. Пример ОМБ показан на рисунке \ref{img:rbm}. Он состоит из видимых и скрытых слоев. Отличие от МСП в том, что нейроны из слоя $v$ могут воздействовать на нейроны из скрытого слоя $h$, и это работает и наоборот. В МСП входной вектор воздействует на скрытые элементы, но обратный процесс невозможен. Недостатком ОМБ является сложность процесса обучения. ОМБ можно накладывать друг на друга для создания более глубоких моделей, называемых сетями с глубоким доверием \cite{beginguidetorbm}.

\img{80mm}{rbm}{Ограниченная машина Больцмана}

\FloatBarrier

\subsubsection*{Автокодировщик --- АК}

АК разработаны для целей неконтролируемого обучения. АК пытается скопировать ввод в вывод. Они часто используются для получения компактных представлений данных. Поэтому их применение находится в области уменьшения размерности (алгоритмы уменьшения размерности являются одним из типичных методов машинного обучения). Внутри АК есть скрытый слой, описывающий код, представляющий входные данные. АК устроен так, что он не копирует ввод точно, а только приближает его. Это может привести к обнаружению полезных шаблонов на этапах данных, поскольку АК вынужден расставлять приоритеты для определенных аспектов, чтобы сделать копию. Расширенные версии этого алгоритма также используются для инициализации весов более сложных архитектур \cite{introdmachlearn}. Их также можно использовать для решения проблем сетевой безопасности. Пример АК показан на рисунке \ref{img:ae}.

\img{100mm}{ae}{Автокодировщик}

\FloatBarrier

\subsubsection*{Сверточные нейронные сети --- СНС}

СНС --- это специализированные типы искусственных нейронных сетей, которые используются для обработки данных, которые имеют известную топологию, подобную сетке (например, одномерные данные с временной выборкой или пиксельную сетку двумерного изображения) \cite{introdmachlearn}. Изначально они были разработаны для машинного зрения. В отличие от МСП, они не используют полную взаимосвязь между уровнями. Вместо этого они используют набор локально связанных фильтров для выявления корреляций между различными секторами данных. Здесь создается так называемый слой свертки, который <<сканирует>> вход и выдает результат с помощью упомянутых фильтров \cite{deeplearninmob}. СНС улучшает базовый МСП в трех важных областях \cite{introdmachlearn}:
\begin{itemize}
	\item[-] разреженное взаимодействие;
	\item[-] совместное использование параметров;
	\item[-] эквивариантное представление (симметричная функции между двумя пространствами).
\end{itemize}

Эти свойства значительно сокращают количество параметров модели. Ядро свертки (слой) меньше входного слоя из-за более тонких взаимодействий. Совместное использование параметров достигается за счет использования одного и того же ядра свертки для «сканирования» всего входного пространства. Это также снижает риск переобучения. Эквивариантные представления означают, что операции свертки инвариантны относительно перевода, масштаба и формы. Это полезно, например, при распознавании изображений \cite{introdmachlearn}. Примером может служить распознавание дорожных знаков в автономных транспортных средствах, когда дорожный знак может располагаться в разных местах изображения, снятого камерой. Принцип СНС показан на рисунке \ref{img:cnn}.

\img{60mm}{cnn}{Сверточные нейронные сети}

\FloatBarrier

\subsubsection*{Генеративно-состязательная сеть --- ГСС}

ГСС основана на теории игр, где генерирующая сеть должна конкурировать с другой. Таким образом, ГСС представляет собой архитектуру, в которой используются две модели (две нейронные сети). Генераторная модель $G$ служит для аппроксимации требуемых входных данных. Модель разделения $D$ пытается определить, исходит ли выборка входных данных из фактических обучающих данных или из выходных данных генераторной модели $G$. При этом обе нейронные сети обучаются. Алгоритм $G$ обучен максимизировать ошибку $D$. С помощью этой системы обе сети улучшают друг друга. Поэтому ГСС используется для создания новых синтетических данных, которые напоминают реальные данные. Они широко используются в области генерации изображений, видео и аудио. Описанный выше принцип показан на рисунке \ref{img:gan} \cite{deeplearninmob}.

\img{80mm}{gan}{Генеративно-состязательная сеть}

\FloatBarrier

\subsubsection*{Рекуррентная нейронная сеть --- РНС}

РНС используется, когда данные имеют последовательный характер (имеется последовательная связь между выборками, например, данные в таблице как функция времени). Они широко используются в обработке естественного языка или распознавании речи. Их архитектура похожа на другие типы нейронных сетей. Основное отличие состоит в том, что РНС содержит цикл для запоминания и передачи результатов от предыдущих нейронов (слоев). На каждом этапе эти сети производят выходные данные посредством повторяющихся соединений между скрытыми единицами. Его принцип показан на рисунке \ref{img:rnn} \cite{deeplearninmob}.

\img{80mm}{rnn}{Рекуррентная нейронная сеть}

\FloatBarrier

Методы глубокого обучения, как и базовые методы машинного обучения, широко используются в области коммуникационных технологий и приложений. В передаче и принятии сигналов используются различные технологии. В настоящее время более сложные модели глубокого обучения в основном используются для приложений приемников сигналов. Ранние модели МСП и ОМБ служат скорее строительными блоками для более сложных моделей. СНС и ее варианты \cite{quavdeeplearn} в частности были популярны, но для многих конкретных задач также используются другие модели, такие как РНС, ГСС и АК \cite{mitigatingdeeplearn}. Это всегда зависит от конкретной задачи, так как не существует универсальной модели, подходящей для всех решаемых задач. Поэтому все упомянутые выше модели — это всего лишь варианты вышеупомянутого узкого ИИ.

\subsection*{Преимущества и недостатки использования методов ГО в беспроводной связи}

Применять методы глубокого обучения лишь из-за того, что они могут быть функциональны, неэффективно. Во многих случаях традиционные методы, основанные на других алгоритмах, более эффективны. Однако в области беспроводной связи методы ГО находят широкое применение \cite{radiosproof}. В этой области доступно большое количество разнородных данных, где для некоторых задач их обработка традиционными методами была бы затруднительна. В других случаях использование традиционных методов может быть ограничено, и поэтому необходимо искать другие подходы. Применение более сложных методов подавления приемников сигналов (с целью обмана этих самых приемников) в прошлом было чрезвычайно сложной задачей. Достижения в области сигналов связи сделали эту задачу еще более сложной. Здесь сталкиваются с ограничениями классической обработки сигналов, например, в разведывательном приемнике генератора помех, который должен демодулировать неизвестный сигнал. Поэтому здесь можно рассмотреть другой подход, и недавние исследования (например, \cite{recieverbasedondl}) показывают, что использование методов глубокого обучения может быть целесообразным при обработке таких сложных сигналов.

\subsubsection*{Преимущества}

Первым важным преимуществом приложений алгоритма глубокого обучения является извлечение признаков. Эти алгоритмы способны извлекать высокоуровневые признаки из данных со сложной структурой \cite{bigdataanal}. С точки зрения беспроводной связи это одна из важнейших особенностей алгоритмов ГО. Это связано с тем, что среда беспроводной сети очень сложна, и интересующие сигналы могут распространяться на уровне шума или даже ниже. На такие сигналы также влияют различные факторы. Из-за этого демодуляция этих сигналов является сложной задачей. Эта трудность еще больше возрастает, когда рассматривается анализ неизвестного сигнала.

Второе преимущество связано с характеристиками среды (беспроводной сети), в которой исследуется использование методов ГО. Беспроводная сетевая среда производит большой объем данных. Алгоритмы глубокого обучения способны обрабатывать такие объемы данных и могут извлечь из них дополнительную пользу, потому что большие наборы данных для обучения нейронных сетей могут предотвратить переобучение модели \cite{overfittingmeasument} (это означает, что модель будет соответствовать обучающим данным почти идеально, но некорректно обрабатывать новые поступающие данные).

Еще одним преимуществом является обработка неразмеченных данных. Задача состоит в анализе различных неизвестных сигналов приемником-разведчиком постановщика помех. Нет доступных правильных результатов или меток, которые должна получить модель. Модели ГО состоят из различных неконтролируемых моделей, которые могут использовать немаркированные данные и изучать полезные закономерности.

\subsubsection*{Недостатки}

Хотя обработка больших объемов данных является одним из преимуществ, она также имеет один существенный недостаток: зависимость модели от данных. Для достаточной точности модели требуются большие обучающие наборы данных. Беспроводные сети производят большой объем данных, но их сбор может быть дорогим, а также могут возникнуть проблемы с конфиденциальностью \cite{deeplearninmob}. Для сравнения, другие подходы, например слепая демодуляция \cite{blinddespreading}, не требуют таких больших объемов данных для правильного функционирования. Для некоторых из этих подходов требуется всего несколько выборок неизвестного сигнала, который необходимо проанализировать.

Другим недостатком является то, что модели ГО могут требовать больших вычислительных ресурсов. Существует потребность в передовых компонентах параллельных вычислений (например, графических процессорах, высокопроизводительных микросхемах). Эти нейронные сети требуют сложных структур для достижения достаточной точности. Однако место ограничивает использование этих моделей на встроенных и мобильных устройствах \cite{deeplearninmob}.

Нейронные сети обычно имеют множество гиперпараметров \cite{giperparams}, которые можно настроить. Однако нахождение их оптимальных значений является сложной задачей. Количество гиперпараметров растет экспоненциально с глубиной модели \cite{deeplearninmob}. Без правильной настройки результирующая точность модели будет не настолько высокой, насколько это возможно.


\section{Выбор подходящих алгоритмов}

Перед началом сравнения архитектур следует выбрать сравниваемые архитектуры.

\begin{itemize}
	\item[-] Многослойный персептрон --- популярность данной архитектуры в настоящее время снижается из-за сложности и недостаточной для многих сфер производительности. Следовательно, данная архитектура в чистом ее виде не походит для построения вводящих приемник в заблуждение сигналов.
	\item[-] Ограниченная машина Больцмана --- недостатком данной архитектуры является сложность процесса обучения. Зачастую она используется в задачах классификации, тематическом моделировании и снижения размерности данных. Ограниченная машина Больцмана требовательна ко времени, что делает данную архитектуру не подходящей для быстрой генерации требуемых сигналов.
	\item[-] Автокодировщик --- данная архитектура предназначена для получения компактных данных и не подходит для создания новых данных.
	\item[-] Сверточные нейронные сети --- используются для обработки данных с известной топологией. Метод локальных фильтров позволяет значительно сократить количество параметров модели и, как следствие, ускорить процесс обучения и получения результата. Данная архитектура предназначена для распознавания определенных данных и генерации на их основе новых. Таким образом, сверточные нейронные сети подходят для поставленной задачи.
	\item[-] Генеративно-состязательная сеть --- используется для генерации изображений, видео и аудио. Случайный ввод генераторная модель преобразует в данные, которые модель разделения должна определить как ошибку. Таким образом генеративно-состязательная сеть подходит для генерации нужных сигналов.
	\item[-] Рекуррентная нейронная сеть --- используется, когда данные имеют последовательный характер. Сигналы являются именно такими данными. Так как известны случаи, когда рекуррентные нейронные сети использовались для распознавания речи, логично предположить, что для радиосигналов данная архитектура так же подходит.
\end{itemize}

\section{Обзор существующих решений}

\begin{itemize}
	\item[-] СНС 1D --- сверточная нейронная сеть с одномерными сверточными слоями.
	\item[-] СНС 2D --- сверточная нейронная сеть с двухмерными сверточными слоями.
	\item[-] СНС + ДКСП --- комбинация двух сверточных слоев и трех слоев долгой краткосрочной памяти \cite{lstmis}.
	\item[-] Двунаправленный ДКСП --- модель использует двунаправленный рекуррентный уровень, что означает возможность обучения с использованием всей доступной входной информации в прошлом и будущем определенного периода времени \cite{doublelstm}.
\end{itemize}

В таблице \ref{tbl:rez} представлены результирующие параметры, связанные с обучением каждой модели в диапазоне от -20дБ до 18дБ.

\begin{table}[h]
	\centering
	\caption{Классификация архитектур генерации путающего сигнала}
	\label{tbl:rez}
	\begin{tabular}{l|c|c|c|c|}
		 & \text{СНС 1D} & \text{СНС 2} & \text{СНС + ДКСП} & \text{БиДКСП}\\
		\hline
		\text{Время обучения} & 3 \text{ мин} & 6 \text{ мин} & 6 \text{ мин} & 10 \text{ мин} \\
		\text{Точность теста} & 0.56742 & 0.54575 & 0.59781 & 0.60212\\
		\text{Всего параметров} & 67449 & 617483 & 152715 & 117835\\
	\end{tabular}
\end{table}

\FloatBarrier

На рисунке \ref{img:accurasy} представлена зависимость точности классификации от отношения сигнал/шум в дБ.

\img{100mm}{accurasy}{Точность классификации каждой модели в зависимости от отношения сигнал/шум}

\FloatBarrier

Как видно из рисунка \ref{img:accurasy}, при росте отношения сигнал/шум растет и точность обнаружения модуляций сигнала.

\section*{Вывод}

Таким образом, нейронная сеть, являющаяся комбинацией сверточной нейронной сети и долгой краткосрочной памяти, является наиболее точным среди всех рассмотренных. Данный алгоритм может использоваться как для задачи классификации, так и для задачи генерации сигналов. Лучшим по времени обучения и по количеству аргументов и, как следствие, самым быстродействующим является одномерная сверточная нейронная сеть.

В результате, лучшим алгоритмом может являться СНС+ДКСП, если требуется наибольшая точность, или СНС 1D, если требуется наивысшая скорость распознавания и генерации.